{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6c3c39-debf-4c76-be25-019d5ea15089",
   "metadata": {},
   "source": [
    "* Importing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6118044-1c41-4d39-9762-7fec560d73be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('spam.csv',encoding=\"ISO-8859-1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb98c6c-f2c2-4203-ba52-d0e2fe253d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2070c4b-9efa-4ed6-85fb-d3bf31be2185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac1e08d-dd6a-40df-96ab-f82646b24ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "336b6536-720d-412b-a70d-4bf2a65a23fa",
   "metadata": {},
   "source": [
    "* Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1146ec6-cc5c-4518-b231-2906196e58fc",
   "metadata": {},
   "source": [
    "Step 1 : Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6926035d-e5d3-4e30-b34a-dcc1d4b0e01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b9171bb-275a-4d7b-94e5-28c2f311b152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>cleaned_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4                                        cleaned_msg  \n",
       "0        NaN        NaN  Go until jurong point crazy Available only in ...  \n",
       "1        NaN        NaN                            Ok lar Joking wif u oni  \n",
       "2        NaN        NaN  Free entry in 2 a wkly comp to win FA Cup fina...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removePunctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "data['cleaned_msg']=data['v2'].apply(lambda x:removePunctuation(x))\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4747829-f59c-488c-b77a-ec30a5a4b468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95a40105-6a3e-4876-9e42-25e4d91894f2",
   "metadata": {},
   "source": [
    "Step 2 : Lowering Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc5a8bee-eb72-4b8e-9bd9-9086f46a4882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_msg</th>\n",
       "      <th>lowerCase_msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>Will Ì b going to esplanade fr home</td>\n",
       "      <td>will ì b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>Pity  was in mood for that Soany other suggest...</td>\n",
       "      <td>pity  was in mood for that soany other suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>The guy did some bitching but I acted like id ...</td>\n",
       "      <td>the guy did some bitching but i acted like id ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cleaned_msg  \\\n",
       "v1                                                        \n",
       "ham   Go until jurong point crazy Available only in ...   \n",
       "ham                             Ok lar Joking wif u oni   \n",
       "spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "ham         U dun say so early hor U c already then say   \n",
       "ham   Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                 ...   \n",
       "spam  This is the 2nd time we have tried 2 contact u...   \n",
       "ham                 Will Ì b going to esplanade fr home   \n",
       "ham   Pity  was in mood for that Soany other suggest...   \n",
       "ham   The guy did some bitching but I acted like id ...   \n",
       "ham                           Rofl Its true to its name   \n",
       "\n",
       "                                          lowerCase_msg  \n",
       "v1                                                       \n",
       "ham   go until jurong point crazy available only in ...  \n",
       "ham                             ok lar joking wif u oni  \n",
       "spam  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "ham         u dun say so early hor u c already then say  \n",
       "ham   nah i dont think he goes to usf he lives aroun...  \n",
       "...                                                 ...  \n",
       "spam  this is the 2nd time we have tried 2 contact u...  \n",
       "ham                 will ì b going to esplanade fr home  \n",
       "ham   pity  was in mood for that soany other suggest...  \n",
       "ham   the guy did some bitching but i acted like id ...  \n",
       "ham                           rofl its true to its name  \n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lowerCase_msg']=data['cleaned_msg'].apply(lambda x:x.lower())\n",
    "data[['cleaned_msg','lowerCase_msg']].set_index(data['v1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d4d1c-d38f-4b5f-abac-c55e27e8a32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a75a60f-1ebc-4ae8-bdb5-4507a1d50dbd",
   "metadata": {},
   "source": [
    "Step 3 : Tokenization (Word Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630e1b72-7000-4d04-883d-49fdea488b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "def tokenize_words(text):\n",
    " words = word_tokenize(text)\n",
    " return words\n",
    "\n",
    "data['tokenized_msg']=data['lowerCase_msg'].apply(lambda x:tokenize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4346761a-eb48-465e-b345-b8b7d4c99764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>cleaned_msg</th>\n",
       "      <th>lowerCase_msg</th>\n",
       "      <th>tokenized_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    v1                                                 v2 Unnamed: 2  \\\n",
       "0  ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4                                        cleaned_msg  \\\n",
       "0        NaN        NaN  Go until jurong point crazy Available only in ...   \n",
       "\n",
       "                                       lowerCase_msg  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "\n",
       "                                       tokenized_msg  \n",
       "0  [go, until, jurong, point, crazy, available, o...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96614c-96c5-4d56-9ad0-ba528ed412f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1b3c1e3-a59d-456f-a928-736d3234bfaf",
   "metadata": {},
   "source": [
    "Step 4 : Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "013764a9-325d-41ac-a4b8-e4114f7572da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[0:10]\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77c062a5-e6ee-4534-b91a-ae67793dbf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "data['no_stopwords']= data['tokenized_msg'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61613a61-afcc-406a-adc6-1232cbf789e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>cleaned_msg</th>\n",
       "      <th>lowerCase_msg</th>\n",
       "      <th>tokenized_msg</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    v1                                                 v2 Unnamed: 2  \\\n",
       "0  ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4                                        cleaned_msg  \\\n",
       "0        NaN        NaN  Go until jurong point crazy Available only in ...   \n",
       "\n",
       "                                       lowerCase_msg  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "\n",
       "                                       tokenized_msg  \\\n",
       "0  [go, until, jurong, point, crazy, available, o...   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9baf20-d920-4ca9-8973-1947bedccab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c32c7dfc-b81d-4918-ba96-5919b5937984",
   "metadata": {},
   "source": [
    "Step 5 : Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6e1a388-5c53-416f-b49e-428077b06438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "def stemming(text):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
    "    return stem_text\n",
    "data['msg_stemmed']=data['no_stopwords'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6df531ca-66e9-4124-869f-57a8b27cbcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>cleaned_msg</th>\n",
       "      <th>lowerCase_msg</th>\n",
       "      <th>tokenized_msg</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>msg_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    v1                                                 v2 Unnamed: 2  \\\n",
       "0  ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4                                        cleaned_msg  \\\n",
       "0        NaN        NaN  Go until jurong point crazy Available only in ...   \n",
       "\n",
       "                                       lowerCase_msg  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "\n",
       "                                       tokenized_msg  \\\n",
       "0  [go, until, jurong, point, crazy, available, o...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "\n",
       "                                         msg_stemmed  \n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995d993-cc54-4d01-9f75-ad1c8a665e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a49a342-427b-4685-89b1-3f7970924275",
   "metadata": {},
   "source": [
    "Step 6 : Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ebfab65-52ca-4108-9666-70974c563d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "data['msg_lemmatized']=data['msg_stemmed'].apply(lambda x:lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb7c29eb-e55d-475b-9377-7c4d9f686d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>cleaned_msg</th>\n",
       "      <th>lowerCase_msg</th>\n",
       "      <th>tokenized_msg</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>msg_stemmed</th>\n",
       "      <th>msg_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    v1                                                 v2 Unnamed: 2  \\\n",
       "0  ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4                                        cleaned_msg  \\\n",
       "0        NaN        NaN  Go until jurong point crazy Available only in ...   \n",
       "\n",
       "                                       lowerCase_msg  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "\n",
       "                                       tokenized_msg  \\\n",
       "0  [go, until, jurong, point, crazy, available, o...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "\n",
       "                                         msg_stemmed  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "\n",
       "                                      msg_lemmatized  \n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7984d3c-ce3d-42e4-88bc-b0a23a0f6a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['go'],\n",
       " ['jurong'],\n",
       " ['point'],\n",
       " ['crazi'],\n",
       " ['avail'],\n",
       " ['bugi'],\n",
       " ['n'],\n",
       " ['great'],\n",
       " ['world'],\n",
       " ['la'],\n",
       " ['e'],\n",
       " ['buffet'],\n",
       " ['cine'],\n",
       " ['got'],\n",
       " ['amor'],\n",
       " ['wat'],\n",
       " ['ok'],\n",
       " ['lar'],\n",
       " ['joke'],\n",
       " ['wif'],\n",
       " ['u'],\n",
       " ['oni'],\n",
       " ['free'],\n",
       " ['entri'],\n",
       " ['2'],\n",
       " ['wkli'],\n",
       " ['comp'],\n",
       " ['win'],\n",
       " ['fa'],\n",
       " ['cup'],\n",
       " ['final'],\n",
       " ['tkt'],\n",
       " ['21st'],\n",
       " ['may'],\n",
       " ['2005'],\n",
       " ['text'],\n",
       " ['fa'],\n",
       " ['87121'],\n",
       " ['receiv'],\n",
       " ['entri'],\n",
       " ['questionstd'],\n",
       " ['txt'],\n",
       " ['ratetc'],\n",
       " ['appli'],\n",
       " ['08452810075over18'],\n",
       " ['u'],\n",
       " ['dun'],\n",
       " ['say'],\n",
       " ['earli'],\n",
       " ['hor'],\n",
       " ['u'],\n",
       " ['c'],\n",
       " ['alreadi'],\n",
       " ['say'],\n",
       " ['nah'],\n",
       " ['dont'],\n",
       " ['think'],\n",
       " ['goe'],\n",
       " ['usf'],\n",
       " ['live'],\n",
       " ['around'],\n",
       " ['though'],\n",
       " ['freemsg'],\n",
       " ['hey'],\n",
       " ['darl'],\n",
       " ['3'],\n",
       " ['week'],\n",
       " ['word'],\n",
       " ['back'],\n",
       " ['id'],\n",
       " ['like'],\n",
       " ['fun'],\n",
       " ['still'],\n",
       " ['tb'],\n",
       " ['ok'],\n",
       " ['xxx'],\n",
       " ['std'],\n",
       " ['chg'],\n",
       " ['send'],\n",
       " ['å£150'],\n",
       " ['rcv'],\n",
       " ['even'],\n",
       " ['brother'],\n",
       " ['like'],\n",
       " ['speak'],\n",
       " ['treat'],\n",
       " ['like'],\n",
       " ['aid'],\n",
       " ['patent'],\n",
       " ['per'],\n",
       " ['request'],\n",
       " ['mell'],\n",
       " ['mell'],\n",
       " ['oru'],\n",
       " ['minnaminungint'],\n",
       " ['nurungu'],\n",
       " ['vettam'],\n",
       " ['set'],\n",
       " ['callertun'],\n",
       " ['caller'],\n",
       " ['press'],\n",
       " ['9'],\n",
       " ['copi'],\n",
       " ['friend'],\n",
       " ['callertun'],\n",
       " ['winner'],\n",
       " ['valu'],\n",
       " ['network'],\n",
       " ['custom'],\n",
       " ['select'],\n",
       " ['receivea'],\n",
       " ['å£900'],\n",
       " ['prize'],\n",
       " ['reward'],\n",
       " ['claim'],\n",
       " ['call'],\n",
       " ['09061701461'],\n",
       " ['claim'],\n",
       " ['code'],\n",
       " ['kl341'],\n",
       " ['valid'],\n",
       " ['12'],\n",
       " ['hour'],\n",
       " ['mobil'],\n",
       " ['11'],\n",
       " ['month'],\n",
       " ['u'],\n",
       " ['r'],\n",
       " ['entitl'],\n",
       " ['updat'],\n",
       " ['latest'],\n",
       " ['colour'],\n",
       " ['mobil'],\n",
       " ['camera'],\n",
       " ['free'],\n",
       " ['call'],\n",
       " ['mobil'],\n",
       " ['updat'],\n",
       " ['co'],\n",
       " ['free'],\n",
       " ['08002986030'],\n",
       " ['im'],\n",
       " ['gon'],\n",
       " ['na'],\n",
       " ['home'],\n",
       " ['soon'],\n",
       " ['dont'],\n",
       " ['want'],\n",
       " ['talk'],\n",
       " ['stuff'],\n",
       " ['anymor'],\n",
       " ['tonight'],\n",
       " ['k'],\n",
       " ['ive'],\n",
       " ['cri'],\n",
       " ['enough'],\n",
       " ['today'],\n",
       " ['six'],\n",
       " ['chanc'],\n",
       " ['win'],\n",
       " ['cash'],\n",
       " ['100'],\n",
       " ['20000'],\n",
       " ['pound'],\n",
       " ['txt'],\n",
       " ['csh11'],\n",
       " ['send'],\n",
       " ['87575'],\n",
       " ['cost'],\n",
       " ['150pday'],\n",
       " ['6day'],\n",
       " ['16'],\n",
       " ['tsandc'],\n",
       " ['appli'],\n",
       " ['repli'],\n",
       " ['hl'],\n",
       " ['4'],\n",
       " ['info'],\n",
       " ['urgent'],\n",
       " ['1'],\n",
       " ['week'],\n",
       " ['free'],\n",
       " ['membership'],\n",
       " ['å£100000'],\n",
       " ['prize'],\n",
       " ['jackpot'],\n",
       " ['txt'],\n",
       " ['word'],\n",
       " ['claim'],\n",
       " ['81010'],\n",
       " ['tc'],\n",
       " ['wwwdbuknet'],\n",
       " ['lccltd'],\n",
       " ['pobox'],\n",
       " ['4403ldnw1a7rw18'],\n",
       " ['ive'],\n",
       " ['search'],\n",
       " ['right'],\n",
       " ['word'],\n",
       " ['thank'],\n",
       " ['breather'],\n",
       " ['promis'],\n",
       " ['wont'],\n",
       " ['take'],\n",
       " ['help'],\n",
       " ['grant'],\n",
       " ['fulfil'],\n",
       " ['promis'],\n",
       " ['wonder'],\n",
       " ['bless'],\n",
       " ['time'],\n",
       " ['date'],\n",
       " ['sunday'],\n",
       " ['xxxmobilemovieclub'],\n",
       " ['use'],\n",
       " ['credit'],\n",
       " ['click'],\n",
       " ['wap'],\n",
       " ['link'],\n",
       " ['next'],\n",
       " ['txt'],\n",
       " ['messag'],\n",
       " ['click'],\n",
       " ['httpwap'],\n",
       " ['xxxmobilemovieclubcomnqjkgighjjgcbl'],\n",
       " ['oh'],\n",
       " ['kim'],\n",
       " ['watch'],\n",
       " ['eh'],\n",
       " ['u'],\n",
       " ['rememb'],\n",
       " ['2'],\n",
       " ['spell'],\n",
       " ['name'],\n",
       " ['ye'],\n",
       " ['v'],\n",
       " ['naughti'],\n",
       " ['make'],\n",
       " ['v'],\n",
       " ['wet'],\n",
       " ['fine'],\n",
       " ['thatåõ'],\n",
       " ['way'],\n",
       " ['u'],\n",
       " ['feel'],\n",
       " ['thatåõ'],\n",
       " ['way'],\n",
       " ['gota'],\n",
       " ['b'],\n",
       " ['england'],\n",
       " ['v'],\n",
       " ['macedonia'],\n",
       " ['dont'],\n",
       " ['miss'],\n",
       " ['goalsteam'],\n",
       " ['news'],\n",
       " ['txt'],\n",
       " ['ur'],\n",
       " ['nation'],\n",
       " ['team'],\n",
       " ['87077'],\n",
       " ['eg'],\n",
       " ['england'],\n",
       " ['87077'],\n",
       " ['trywal'],\n",
       " ['scotland'],\n",
       " ['4txtì¼120'],\n",
       " ['poboxox36504w45wq'],\n",
       " ['16'],\n",
       " ['serious'],\n",
       " ['spell'],\n",
       " ['name'],\n",
       " ['i\\x89û÷m'],\n",
       " ['go'],\n",
       " ['tri'],\n",
       " ['2'],\n",
       " ['month'],\n",
       " ['ha'],\n",
       " ['ha'],\n",
       " ['joke'],\n",
       " ['ì'],\n",
       " ['pay'],\n",
       " ['first'],\n",
       " ['lar'],\n",
       " ['da'],\n",
       " ['stock'],\n",
       " ['comin'],\n",
       " ['aft'],\n",
       " ['finish'],\n",
       " ['lunch'],\n",
       " ['go'],\n",
       " ['str'],\n",
       " ['lor'],\n",
       " ['ard'],\n",
       " ['3'],\n",
       " ['smth'],\n",
       " ['lor'],\n",
       " ['u'],\n",
       " ['finish'],\n",
       " ['ur'],\n",
       " ['lunch'],\n",
       " ['alreadi'],\n",
       " ['ffffffffff'],\n",
       " ['alright'],\n",
       " ['way'],\n",
       " ['meet'],\n",
       " ['sooner'],\n",
       " ['forc'],\n",
       " ['eat'],\n",
       " ['slice'],\n",
       " ['im'],\n",
       " ['realli'],\n",
       " ['hungri'],\n",
       " ['tho'],\n",
       " ['suck'],\n",
       " ['mark'],\n",
       " ['get'],\n",
       " ['worri'],\n",
       " ['know'],\n",
       " ['im'],\n",
       " ['sick'],\n",
       " ['turn'],\n",
       " ['pizza'],\n",
       " ['lol'],\n",
       " ['lol'],\n",
       " ['alway'],\n",
       " ['convinc'],\n",
       " ['catch'],\n",
       " ['bu'],\n",
       " ['fri'],\n",
       " ['egg'],\n",
       " ['make'],\n",
       " ['tea'],\n",
       " ['eat'],\n",
       " ['mom'],\n",
       " ['left'],\n",
       " ['dinner'],\n",
       " ['feel'],\n",
       " ['love'],\n",
       " ['im'],\n",
       " ['back'],\n",
       " ['amp'],\n",
       " ['pack'],\n",
       " ['car'],\n",
       " ['ill'],\n",
       " ['let'],\n",
       " ['know'],\n",
       " ['there'],\n",
       " ['room'],\n",
       " ['ahhh'],\n",
       " ['work'],\n",
       " ['vagu'],\n",
       " ['rememb'],\n",
       " ['feel'],\n",
       " ['like'],\n",
       " ['lol'],\n",
       " ['wait'],\n",
       " ['that'],\n",
       " ['still'],\n",
       " ['clear'],\n",
       " ['sure'],\n",
       " ['sarcast'],\n",
       " ['that'],\n",
       " ['x'],\n",
       " ['doesnt'],\n",
       " ['want'],\n",
       " ['live'],\n",
       " ['u'],\n",
       " ['yeah'],\n",
       " ['got'],\n",
       " ['2'],\n",
       " ['v'],\n",
       " ['apologet'],\n",
       " ['n'],\n",
       " ['fallen'],\n",
       " ['actin'],\n",
       " ['like'],\n",
       " ['spoilt'],\n",
       " ['child'],\n",
       " ['got'],\n",
       " ['caught'],\n",
       " ['till'],\n",
       " ['2'],\n",
       " ['wont'],\n",
       " ['go'],\n",
       " ['badli'],\n",
       " ['cheer'],\n",
       " ['k'],\n",
       " ['tell'],\n",
       " ['anyth'],\n",
       " ['fear'],\n",
       " ['faint'],\n",
       " ['housework'],\n",
       " ['quick'],\n",
       " ['cuppa'],\n",
       " ['thank'],\n",
       " ['subscript'],\n",
       " ['rington'],\n",
       " ['uk'],\n",
       " ['mobil'],\n",
       " ['charg'],\n",
       " ['å£5month'],\n",
       " ['plea'],\n",
       " ['confirm'],\n",
       " ['repli'],\n",
       " ['ye'],\n",
       " ['repli'],\n",
       " ['charg'],\n",
       " ['yup'],\n",
       " ['ok'],\n",
       " ['go'],\n",
       " ['home'],\n",
       " ['look'],\n",
       " ['time'],\n",
       " ['msg'],\n",
       " ['ì'],\n",
       " ['xuhui'],\n",
       " ['go'],\n",
       " ['learn'],\n",
       " ['2nd'],\n",
       " ['may'],\n",
       " ['lesson'],\n",
       " ['8am'],\n",
       " ['oop'],\n",
       " ['ill'],\n",
       " ['let'],\n",
       " ['know'],\n",
       " ['roommat'],\n",
       " ['done'],\n",
       " ['see'],\n",
       " ['letter'],\n",
       " ['b'],\n",
       " ['car'],\n",
       " ['anyth'],\n",
       " ['lor'],\n",
       " ['u'],\n",
       " ['decid'],\n",
       " ['hello'],\n",
       " ['how'],\n",
       " ['saturday'],\n",
       " ['go'],\n",
       " ['text'],\n",
       " ['see'],\n",
       " ['youd'],\n",
       " ['decid'],\n",
       " ['anyth'],\n",
       " ['tomo'],\n",
       " ['im'],\n",
       " ['tri'],\n",
       " ['invit'],\n",
       " ['anyth'],\n",
       " ['pl'],\n",
       " ['go'],\n",
       " ['ahead'],\n",
       " ['watt'],\n",
       " ['want'],\n",
       " ['sure'],\n",
       " ['great'],\n",
       " ['weekend'],\n",
       " ['abiola'],\n",
       " ['forget'],\n",
       " ['tell'],\n",
       " ['want'],\n",
       " ['need'],\n",
       " ['crave'],\n",
       " ['love'],\n",
       " ['sweet'],\n",
       " ['arabian'],\n",
       " ['steed'],\n",
       " ['mmmmmm'],\n",
       " ['yummi'],\n",
       " ['07732584351'],\n",
       " ['rodger'],\n",
       " ['burn'],\n",
       " ['msg'],\n",
       " ['tri'],\n",
       " ['call'],\n",
       " ['repli'],\n",
       " ['sm'],\n",
       " ['free'],\n",
       " ['nokia'],\n",
       " ['mobil'],\n",
       " ['free'],\n",
       " ['camcord'],\n",
       " ['plea'],\n",
       " ['call'],\n",
       " ['08000930705'],\n",
       " ['deliveri'],\n",
       " ['tomorrow'],\n",
       " ['see'],\n",
       " ['great'],\n",
       " ['hope'],\n",
       " ['like'],\n",
       " ['man'],\n",
       " ['well'],\n",
       " ['endow'],\n",
       " ['ltgt'],\n",
       " ['inch'],\n",
       " ['callsmessagesmiss'],\n",
       " ['call'],\n",
       " ['didnt'],\n",
       " ['get'],\n",
       " ['hep'],\n",
       " ['b'],\n",
       " ['immunis'],\n",
       " ['nigeria'],\n",
       " ['fair'],\n",
       " ['enough'],\n",
       " ['anyth'],\n",
       " ['go'],\n",
       " ['yeah'],\n",
       " ['hope'],\n",
       " ['tyler'],\n",
       " ['cant'],\n",
       " ['could'],\n",
       " ['mayb'],\n",
       " ['ask'],\n",
       " ['around'],\n",
       " ['bit'],\n",
       " ['u'],\n",
       " ['dont'],\n",
       " ['know'],\n",
       " ['stubborn'],\n",
       " ['didnt'],\n",
       " ['even'],\n",
       " ['want'],\n",
       " ['go'],\n",
       " ['hospit'],\n",
       " ['kept'],\n",
       " ['tell'],\n",
       " ['mark'],\n",
       " ['im'],\n",
       " ['weak'],\n",
       " ['sucker'],\n",
       " ['hospit'],\n",
       " ['weak'],\n",
       " ['sucker'],\n",
       " ['think'],\n",
       " ['first'],\n",
       " ['time'],\n",
       " ['saw'],\n",
       " ['class'],\n",
       " ['gram'],\n",
       " ['usual'],\n",
       " ['run'],\n",
       " ['like'],\n",
       " ['ltgt'],\n",
       " ['half'],\n",
       " ['eighth'],\n",
       " ['smarter'],\n",
       " ['though'],\n",
       " ['get'],\n",
       " ['almost'],\n",
       " ['whole'],\n",
       " ['second'],\n",
       " ['gram'],\n",
       " ['ltgt'],\n",
       " ['k'],\n",
       " ['fyi'],\n",
       " ['x'],\n",
       " ['ride'],\n",
       " ['earli'],\n",
       " ['tomorrow'],\n",
       " ['morn'],\n",
       " ['he'],\n",
       " ['crash'],\n",
       " ['place'],\n",
       " ['tonight'],\n",
       " ['wow'],\n",
       " ['never'],\n",
       " ['realiz'],\n",
       " ['embarass'],\n",
       " ['accomod'],\n",
       " ['thought'],\n",
       " ['like'],\n",
       " ['sinc'],\n",
       " ['best'],\n",
       " ['could'],\n",
       " ['alway'],\n",
       " ['seem'],\n",
       " ['happi'],\n",
       " ['cave'],\n",
       " ['im'],\n",
       " ['sorri'],\n",
       " ['didnt'],\n",
       " ['dont'],\n",
       " ['give'],\n",
       " ['im'],\n",
       " ['sorri'],\n",
       " ['offer'],\n",
       " ['im'],\n",
       " ['sorri'],\n",
       " ['room'],\n",
       " ['embarass'],\n",
       " ['sm'],\n",
       " ['ac'],\n",
       " ['sptv'],\n",
       " ['new'],\n",
       " ['jersey'],\n",
       " ['devil'],\n",
       " ['detroit'],\n",
       " ['red'],\n",
       " ['wing'],\n",
       " ['play'],\n",
       " ['ice'],\n",
       " ['hockey'],\n",
       " ['correct'],\n",
       " ['incorrect'],\n",
       " ['end'],\n",
       " ['repli'],\n",
       " ['end'],\n",
       " ['sptv'],\n",
       " ['know'],\n",
       " ['mallika'],\n",
       " ['sherawat'],\n",
       " ['yesterday'],\n",
       " ['find'],\n",
       " ['lturlgt'],\n",
       " ['congrat'],\n",
       " ['1'],\n",
       " ['year'],\n",
       " ['special'],\n",
       " ['cinema'],\n",
       " ['pas'],\n",
       " ['2'],\n",
       " ['call'],\n",
       " ['09061209465'],\n",
       " ['c'],\n",
       " ['suprman'],\n",
       " ['v'],\n",
       " ['matrix3'],\n",
       " ['starwars3'],\n",
       " ['etc'],\n",
       " ['4'],\n",
       " ['free'],\n",
       " ['bx420ip45w'],\n",
       " ['150pm'],\n",
       " ['dont'],\n",
       " ['miss'],\n",
       " ['sorri'],\n",
       " ['ill'],\n",
       " ['call'],\n",
       " ['later'],\n",
       " ['meet'],\n",
       " ['tell'],\n",
       " ['reach'],\n",
       " ['yesgauti'],\n",
       " ['sehwag'],\n",
       " ['odi'],\n",
       " ['seri'],\n",
       " ['gon'],\n",
       " ['na'],\n",
       " ['pick'],\n",
       " ['1'],\n",
       " ['burger'],\n",
       " ['way'],\n",
       " ['home'],\n",
       " ['cant'],\n",
       " ['even'],\n",
       " ['move'],\n",
       " ['pain'],\n",
       " ['kill'],\n",
       " ['ha'],\n",
       " ['ha'],\n",
       " ['ha'],\n",
       " ['good'],\n",
       " ['joke'],\n",
       " ['girl'],\n",
       " ['situat'],\n",
       " ['seeker'],\n",
       " ['part'],\n",
       " ['check'],\n",
       " ['iq'],\n",
       " ['sorri'],\n",
       " ['roommat'],\n",
       " ['took'],\n",
       " ['forev'],\n",
       " ['ok'],\n",
       " ['come'],\n",
       " ['ok'],\n",
       " ['lar'],\n",
       " ['doubl'],\n",
       " ['check'],\n",
       " ['wif'],\n",
       " ['da'],\n",
       " ['hair'],\n",
       " ['dresser'],\n",
       " ['alreadi'],\n",
       " ['said'],\n",
       " ['wun'],\n",
       " ['cut'],\n",
       " ['v'],\n",
       " ['short'],\n",
       " ['said'],\n",
       " ['cut'],\n",
       " ['look'],\n",
       " ['nice'],\n",
       " ['valu'],\n",
       " ['custom'],\n",
       " ['plea'],\n",
       " ['advis'],\n",
       " ['follow'],\n",
       " ['recent'],\n",
       " ['review'],\n",
       " ['mob'],\n",
       " ['award'],\n",
       " ['å£1500'],\n",
       " ['bonu'],\n",
       " ['prize'],\n",
       " ['call'],\n",
       " ['09066364589'],\n",
       " ['today'],\n",
       " ['song'],\n",
       " ['dedic'],\n",
       " ['day'],\n",
       " ['song'],\n",
       " ['u'],\n",
       " ['dedic'],\n",
       " ['send'],\n",
       " ['ur'],\n",
       " ['valuabl'],\n",
       " ['frnd'],\n",
       " ['first'],\n",
       " ['rpli'],\n",
       " ['urgent'],\n",
       " ['ur'],\n",
       " ['award'],\n",
       " ['complimentari'],\n",
       " ['trip'],\n",
       " ['eurodisinc'],\n",
       " ['trav'],\n",
       " ['acoentry41'],\n",
       " ['å£1000'],\n",
       " ['claim'],\n",
       " ['txt'],\n",
       " ['di'],\n",
       " ['87121'],\n",
       " ['186å£150morefrmmob'],\n",
       " ['shracomorsglsuplt10'],\n",
       " ['ls1'],\n",
       " ['3aj'],\n",
       " ['hear'],\n",
       " ['new'],\n",
       " ['divorc'],\n",
       " ['barbi'],\n",
       " ['come'],\n",
       " ['ken'],\n",
       " ['stuff'],\n",
       " ['plane'],\n",
       " ['give'],\n",
       " ['month'],\n",
       " ['end'],\n",
       " ['wah'],\n",
       " ['lucki'],\n",
       " ['man'],\n",
       " ['save'],\n",
       " ['money'],\n",
       " ['hee'],\n",
       " ['finish'],\n",
       " ['class'],\n",
       " ['hi'],\n",
       " ['babe'],\n",
       " ['im'],\n",
       " ['home'],\n",
       " ['wan'],\n",
       " ['na'],\n",
       " ['someth'],\n",
       " ['xx'],\n",
       " ['kkwhere'],\n",
       " ['youhow'],\n",
       " ['perform'],\n",
       " ['u'],\n",
       " ['call'],\n",
       " ['wait'],\n",
       " ['machan'],\n",
       " ['call'],\n",
       " ['free'],\n",
       " ['that'],\n",
       " ['cool'],\n",
       " ['gentleman'],\n",
       " ['treat'],\n",
       " ['digniti'],\n",
       " ['respect'],\n",
       " ['like'],\n",
       " ['peopl'],\n",
       " ['much'],\n",
       " ['shi'],\n",
       " ['pa'],\n",
       " ['oper'],\n",
       " ['ltgt'],\n",
       " ['still'],\n",
       " ['look'],\n",
       " ['job'],\n",
       " ['much'],\n",
       " ['ta'],\n",
       " ['earn'],\n",
       " ['sorri'],\n",
       " ['ill'],\n",
       " ['call'],\n",
       " ['later'],\n",
       " ['k'],\n",
       " ['call'],\n",
       " ['ah'],\n",
       " ['ok'],\n",
       " ['way'],\n",
       " ['home'],\n",
       " ['hi'],\n",
       " ['hi'],\n",
       " ['place'],\n",
       " ['man'],\n",
       " ['yup'],\n",
       " ['next'],\n",
       " ['stop'],\n",
       " ['call'],\n",
       " ['later'],\n",
       " ['dont'],\n",
       " ['network'],\n",
       " ['urgnt'],\n",
       " ['sm'],\n",
       " ['real'],\n",
       " ['u'],\n",
       " ['get'],\n",
       " ['yo'],\n",
       " ['need'],\n",
       " ['2'],\n",
       " ['ticket'],\n",
       " ['one'],\n",
       " ['jacket'],\n",
       " ['im'],\n",
       " ['done'],\n",
       " ['alreadi'],\n",
       " ['use'],\n",
       " ['multi'],\n",
       " ['ye'],\n",
       " ['start'],\n",
       " ['send'],\n",
       " ['request'],\n",
       " ['make'],\n",
       " ['pain'],\n",
       " ['came'],\n",
       " ['back'],\n",
       " ['im'],\n",
       " ['back'],\n",
       " ['bed'],\n",
       " ['doubl'],\n",
       " ['coin'],\n",
       " ['factori'],\n",
       " ['got'],\n",
       " ['ta'],\n",
       " ['cash'],\n",
       " ['nitro'],\n",
       " ['im'],\n",
       " ['realli'],\n",
       " ['still'],\n",
       " ['tonight'],\n",
       " ['babe'],\n",
       " ['ela'],\n",
       " ['kanoil'],\n",
       " ['download'],\n",
       " ['come'],\n",
       " ['wen'],\n",
       " ['ur'],\n",
       " ['free'],\n",
       " ['yeah'],\n",
       " ['don\\x89û÷t'],\n",
       " ['stand'],\n",
       " ['close'],\n",
       " ['tho'],\n",
       " ['you\\x89û÷ll'],\n",
       " ['catch'],\n",
       " ['someth'],\n",
       " ['sorri'],\n",
       " ['pain'],\n",
       " ['ok'],\n",
       " ['meet'],\n",
       " ['anoth'],\n",
       " ['night'],\n",
       " ['spent'],\n",
       " ['late'],\n",
       " ['afternoon'],\n",
       " ['casualti'],\n",
       " ['mean'],\n",
       " ['havent'],\n",
       " ['done'],\n",
       " ['stuff42moro'],\n",
       " ['includ'],\n",
       " ['time'],\n",
       " ['sheet'],\n",
       " ['sorri'],\n",
       " ['smile'],\n",
       " ['pleasur'],\n",
       " ['smile'],\n",
       " ['pain'],\n",
       " ['smile'],\n",
       " ['troubl'],\n",
       " ['pour'],\n",
       " ['like'],\n",
       " ['rain'],\n",
       " ['smile'],\n",
       " ['sum1'],\n",
       " ['hurt'],\n",
       " ['u'],\n",
       " ['smile'],\n",
       " ['becoz'],\n",
       " ['someon'],\n",
       " ['still'],\n",
       " ['love'],\n",
       " ['see'],\n",
       " ['u'],\n",
       " ['smile'],\n",
       " ['plea'],\n",
       " ['call'],\n",
       " ['custom'],\n",
       " ['servic'],\n",
       " ['repres'],\n",
       " ['0800'],\n",
       " ['169'],\n",
       " ['6031'],\n",
       " ['10am9pm'],\n",
       " ['guarante'],\n",
       " ['å£1000'],\n",
       " ['cash'],\n",
       " ['å£5000'],\n",
       " ['prize'],\n",
       " ['havent'],\n",
       " ['plan'],\n",
       " ['buy'],\n",
       " ['later'],\n",
       " ['check'],\n",
       " ['alreadi'],\n",
       " ['lido'],\n",
       " ['got'],\n",
       " ['530'],\n",
       " ['show'],\n",
       " ['e'],\n",
       " ['afternoon'],\n",
       " ['u'],\n",
       " ['finish'],\n",
       " ['work'],\n",
       " ['alreadi'],\n",
       " ['free'],\n",
       " ['rington'],\n",
       " ['wait'],\n",
       " ['collect'],\n",
       " ['simpli'],\n",
       " ['text'],\n",
       " ['password'],\n",
       " ['mix'],\n",
       " ['85069'],\n",
       " ['verifi'],\n",
       " ['get'],\n",
       " ['usher'],\n",
       " ['britney'],\n",
       " ['fml'],\n",
       " ['watch'],\n",
       " ['telugu'],\n",
       " ['moviewat'],\n",
       " ['abt'],\n",
       " ['u'],\n",
       " ['see'],\n",
       " ['finish'],\n",
       " ['load'],\n",
       " ['loan'],\n",
       " ['pay'],\n",
       " ['hi'],\n",
       " ['wk'],\n",
       " ['ok'],\n",
       " ['hol'],\n",
       " ['ye'],\n",
       " ['bit'],\n",
       " ['run'],\n",
       " ['forgot'],\n",
       " ['hairdress'],\n",
       " ['appoint'],\n",
       " ['four'],\n",
       " ['need'],\n",
       " ['get'],\n",
       " ['home'],\n",
       " ['n'],\n",
       " ['shower'],\n",
       " ['beforehand'],\n",
       " ['caus'],\n",
       " ['prob'],\n",
       " ['u'],\n",
       " ['ham'],\n",
       " ['plea'],\n",
       " ['dont'],\n",
       " ['text'],\n",
       " ['anymor'],\n",
       " ['noth'],\n",
       " ['el'],\n",
       " ['say'],\n",
       " ['okay'],\n",
       " ['name'],\n",
       " ['ur'],\n",
       " ['price'],\n",
       " ['long'],\n",
       " ['legal'],\n",
       " ['wen'],\n",
       " ['pick'],\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = []\n",
    "for sublist in data['msg_lemmatized']:\n",
    "    for value in sublist:\n",
    "        list1.append(value.split(','))\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc5ff974-a4d4-4e73-a452-f4e7eb6b0aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazi',\n",
       " 'avail',\n",
       " 'bugi',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'got',\n",
       " 'amor',\n",
       " 'wat',\n",
       " 'ok',\n",
       " 'lar',\n",
       " 'joke',\n",
       " 'wif',\n",
       " 'u',\n",
       " 'oni',\n",
       " 'free',\n",
       " 'entri',\n",
       " '2',\n",
       " 'wkli',\n",
       " 'comp',\n",
       " 'win',\n",
       " 'fa',\n",
       " 'cup',\n",
       " 'final',\n",
       " 'tkt',\n",
       " '21st',\n",
       " 'may',\n",
       " '2005',\n",
       " 'text',\n",
       " 'fa',\n",
       " '87121',\n",
       " 'receiv',\n",
       " 'entri',\n",
       " 'questionstd',\n",
       " 'txt',\n",
       " 'ratetc',\n",
       " 'appli',\n",
       " '08452810075over18',\n",
       " 'u',\n",
       " 'dun',\n",
       " 'say',\n",
       " 'earli',\n",
       " 'hor',\n",
       " 'u',\n",
       " 'c',\n",
       " 'alreadi',\n",
       " 'say',\n",
       " 'nah',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'goe',\n",
       " 'usf',\n",
       " 'live',\n",
       " 'around',\n",
       " 'though',\n",
       " 'freemsg',\n",
       " 'hey',\n",
       " 'darl',\n",
       " '3',\n",
       " 'week',\n",
       " 'word',\n",
       " 'back',\n",
       " 'id',\n",
       " 'like',\n",
       " 'fun',\n",
       " 'still',\n",
       " 'tb',\n",
       " 'ok',\n",
       " 'xxx',\n",
       " 'std',\n",
       " 'chg',\n",
       " 'send',\n",
       " 'å£150',\n",
       " 'rcv',\n",
       " 'even',\n",
       " 'brother',\n",
       " 'like',\n",
       " 'speak',\n",
       " 'treat',\n",
       " 'like',\n",
       " 'aid',\n",
       " 'patent',\n",
       " 'per',\n",
       " 'request',\n",
       " 'mell',\n",
       " 'mell',\n",
       " 'oru',\n",
       " 'minnaminungint',\n",
       " 'nurungu',\n",
       " 'vettam',\n",
       " 'set',\n",
       " 'callertun',\n",
       " 'caller',\n",
       " 'press',\n",
       " '9',\n",
       " 'copi',\n",
       " 'friend',\n",
       " 'callertun',\n",
       " 'winner',\n",
       " 'valu',\n",
       " 'network',\n",
       " 'custom',\n",
       " 'select',\n",
       " 'receivea',\n",
       " 'å£900',\n",
       " 'prize',\n",
       " 'reward',\n",
       " 'claim',\n",
       " 'call',\n",
       " '09061701461',\n",
       " 'claim',\n",
       " 'code',\n",
       " 'kl341',\n",
       " 'valid',\n",
       " '12',\n",
       " 'hour',\n",
       " 'mobil',\n",
       " '11',\n",
       " 'month',\n",
       " 'u',\n",
       " 'r',\n",
       " 'entitl',\n",
       " 'updat',\n",
       " 'latest',\n",
       " 'colour',\n",
       " 'mobil',\n",
       " 'camera',\n",
       " 'free',\n",
       " 'call',\n",
       " 'mobil',\n",
       " 'updat',\n",
       " 'co',\n",
       " 'free',\n",
       " '08002986030',\n",
       " 'im',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'home',\n",
       " 'soon',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'talk',\n",
       " 'stuff',\n",
       " 'anymor',\n",
       " 'tonight',\n",
       " 'k',\n",
       " 'ive',\n",
       " 'cri',\n",
       " 'enough',\n",
       " 'today',\n",
       " 'six',\n",
       " 'chanc',\n",
       " 'win',\n",
       " 'cash',\n",
       " '100',\n",
       " '20000',\n",
       " 'pound',\n",
       " 'txt',\n",
       " 'csh11',\n",
       " 'send',\n",
       " '87575',\n",
       " 'cost',\n",
       " '150pday',\n",
       " '6day',\n",
       " '16',\n",
       " 'tsandc',\n",
       " 'appli',\n",
       " 'repli',\n",
       " 'hl',\n",
       " '4',\n",
       " 'info',\n",
       " 'urgent',\n",
       " '1',\n",
       " 'week',\n",
       " 'free',\n",
       " 'membership',\n",
       " 'å£100000',\n",
       " 'prize',\n",
       " 'jackpot',\n",
       " 'txt',\n",
       " 'word',\n",
       " 'claim',\n",
       " '81010',\n",
       " 'tc',\n",
       " 'wwwdbuknet',\n",
       " 'lccltd',\n",
       " 'pobox',\n",
       " '4403ldnw1a7rw18',\n",
       " 'ive',\n",
       " 'search',\n",
       " 'right',\n",
       " 'word',\n",
       " 'thank',\n",
       " 'breather',\n",
       " 'promis',\n",
       " 'wont',\n",
       " 'take',\n",
       " 'help',\n",
       " 'grant',\n",
       " 'fulfil',\n",
       " 'promis',\n",
       " 'wonder',\n",
       " 'bless',\n",
       " 'time',\n",
       " 'date',\n",
       " 'sunday',\n",
       " 'xxxmobilemovieclub',\n",
       " 'use',\n",
       " 'credit',\n",
       " 'click',\n",
       " 'wap',\n",
       " 'link',\n",
       " 'next',\n",
       " 'txt',\n",
       " 'messag',\n",
       " 'click',\n",
       " 'httpwap',\n",
       " 'xxxmobilemovieclubcomnqjkgighjjgcbl',\n",
       " 'oh',\n",
       " 'kim',\n",
       " 'watch',\n",
       " 'eh',\n",
       " 'u',\n",
       " 'rememb',\n",
       " '2',\n",
       " 'spell',\n",
       " 'name',\n",
       " 'ye',\n",
       " 'v',\n",
       " 'naughti',\n",
       " 'make',\n",
       " 'v',\n",
       " 'wet',\n",
       " 'fine',\n",
       " 'thatåõ',\n",
       " 'way',\n",
       " 'u',\n",
       " 'feel',\n",
       " 'thatåõ',\n",
       " 'way',\n",
       " 'gota',\n",
       " 'b',\n",
       " 'england',\n",
       " 'v',\n",
       " 'macedonia',\n",
       " 'dont',\n",
       " 'miss',\n",
       " 'goalsteam',\n",
       " 'news',\n",
       " 'txt',\n",
       " 'ur',\n",
       " 'nation',\n",
       " 'team',\n",
       " '87077',\n",
       " 'eg',\n",
       " 'england',\n",
       " '87077',\n",
       " 'trywal',\n",
       " 'scotland',\n",
       " '4txtì¼120',\n",
       " 'poboxox36504w45wq',\n",
       " '16',\n",
       " 'serious',\n",
       " 'spell',\n",
       " 'name',\n",
       " 'i\\x89û÷m',\n",
       " 'go',\n",
       " 'tri',\n",
       " '2',\n",
       " 'month',\n",
       " 'ha',\n",
       " 'ha',\n",
       " 'joke',\n",
       " 'ì',\n",
       " 'pay',\n",
       " 'first',\n",
       " 'lar',\n",
       " 'da',\n",
       " 'stock',\n",
       " 'comin',\n",
       " 'aft',\n",
       " 'finish',\n",
       " 'lunch',\n",
       " 'go',\n",
       " 'str',\n",
       " 'lor',\n",
       " 'ard',\n",
       " '3',\n",
       " 'smth',\n",
       " 'lor',\n",
       " 'u',\n",
       " 'finish',\n",
       " 'ur',\n",
       " 'lunch',\n",
       " 'alreadi',\n",
       " 'ffffffffff',\n",
       " 'alright',\n",
       " 'way',\n",
       " 'meet',\n",
       " 'sooner',\n",
       " 'forc',\n",
       " 'eat',\n",
       " 'slice',\n",
       " 'im',\n",
       " 'realli',\n",
       " 'hungri',\n",
       " 'tho',\n",
       " 'suck',\n",
       " 'mark',\n",
       " 'get',\n",
       " 'worri',\n",
       " 'know',\n",
       " 'im',\n",
       " 'sick',\n",
       " 'turn',\n",
       " 'pizza',\n",
       " 'lol',\n",
       " 'lol',\n",
       " 'alway',\n",
       " 'convinc',\n",
       " 'catch',\n",
       " 'bu',\n",
       " 'fri',\n",
       " 'egg',\n",
       " 'make',\n",
       " 'tea',\n",
       " 'eat',\n",
       " 'mom',\n",
       " 'left',\n",
       " 'dinner',\n",
       " 'feel',\n",
       " 'love',\n",
       " 'im',\n",
       " 'back',\n",
       " 'amp',\n",
       " 'pack',\n",
       " 'car',\n",
       " 'ill',\n",
       " 'let',\n",
       " 'know',\n",
       " 'there',\n",
       " 'room',\n",
       " 'ahhh',\n",
       " 'work',\n",
       " 'vagu',\n",
       " 'rememb',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'lol',\n",
       " 'wait',\n",
       " 'that',\n",
       " 'still',\n",
       " 'clear',\n",
       " 'sure',\n",
       " 'sarcast',\n",
       " 'that',\n",
       " 'x',\n",
       " 'doesnt',\n",
       " 'want',\n",
       " 'live',\n",
       " 'u',\n",
       " 'yeah',\n",
       " 'got',\n",
       " '2',\n",
       " 'v',\n",
       " 'apologet',\n",
       " 'n',\n",
       " 'fallen',\n",
       " 'actin',\n",
       " 'like',\n",
       " 'spoilt',\n",
       " 'child',\n",
       " 'got',\n",
       " 'caught',\n",
       " 'till',\n",
       " '2',\n",
       " 'wont',\n",
       " 'go',\n",
       " 'badli',\n",
       " 'cheer',\n",
       " 'k',\n",
       " 'tell',\n",
       " 'anyth',\n",
       " 'fear',\n",
       " 'faint',\n",
       " 'housework',\n",
       " 'quick',\n",
       " 'cuppa',\n",
       " 'thank',\n",
       " 'subscript',\n",
       " 'rington',\n",
       " 'uk',\n",
       " 'mobil',\n",
       " 'charg',\n",
       " 'å£5month',\n",
       " 'plea',\n",
       " 'confirm',\n",
       " 'repli',\n",
       " 'ye',\n",
       " 'repli',\n",
       " 'charg',\n",
       " 'yup',\n",
       " 'ok',\n",
       " 'go',\n",
       " 'home',\n",
       " 'look',\n",
       " 'time',\n",
       " 'msg',\n",
       " 'ì',\n",
       " 'xuhui',\n",
       " 'go',\n",
       " 'learn',\n",
       " '2nd',\n",
       " 'may',\n",
       " 'lesson',\n",
       " '8am',\n",
       " 'oop',\n",
       " 'ill',\n",
       " 'let',\n",
       " 'know',\n",
       " 'roommat',\n",
       " 'done',\n",
       " 'see',\n",
       " 'letter',\n",
       " 'b',\n",
       " 'car',\n",
       " 'anyth',\n",
       " 'lor',\n",
       " 'u',\n",
       " 'decid',\n",
       " 'hello',\n",
       " 'how',\n",
       " 'saturday',\n",
       " 'go',\n",
       " 'text',\n",
       " 'see',\n",
       " 'youd',\n",
       " 'decid',\n",
       " 'anyth',\n",
       " 'tomo',\n",
       " 'im',\n",
       " 'tri',\n",
       " 'invit',\n",
       " 'anyth',\n",
       " 'pl',\n",
       " 'go',\n",
       " 'ahead',\n",
       " 'watt',\n",
       " 'want',\n",
       " 'sure',\n",
       " 'great',\n",
       " 'weekend',\n",
       " 'abiola',\n",
       " 'forget',\n",
       " 'tell',\n",
       " 'want',\n",
       " 'need',\n",
       " 'crave',\n",
       " 'love',\n",
       " 'sweet',\n",
       " 'arabian',\n",
       " 'steed',\n",
       " 'mmmmmm',\n",
       " 'yummi',\n",
       " '07732584351',\n",
       " 'rodger',\n",
       " 'burn',\n",
       " 'msg',\n",
       " 'tri',\n",
       " 'call',\n",
       " 'repli',\n",
       " 'sm',\n",
       " 'free',\n",
       " 'nokia',\n",
       " 'mobil',\n",
       " 'free',\n",
       " 'camcord',\n",
       " 'plea',\n",
       " 'call',\n",
       " '08000930705',\n",
       " 'deliveri',\n",
       " 'tomorrow',\n",
       " 'see',\n",
       " 'great',\n",
       " 'hope',\n",
       " 'like',\n",
       " 'man',\n",
       " 'well',\n",
       " 'endow',\n",
       " 'ltgt',\n",
       " 'inch',\n",
       " 'callsmessagesmiss',\n",
       " 'call',\n",
       " 'didnt',\n",
       " 'get',\n",
       " 'hep',\n",
       " 'b',\n",
       " 'immunis',\n",
       " 'nigeria',\n",
       " 'fair',\n",
       " 'enough',\n",
       " 'anyth',\n",
       " 'go',\n",
       " 'yeah',\n",
       " 'hope',\n",
       " 'tyler',\n",
       " 'cant',\n",
       " 'could',\n",
       " 'mayb',\n",
       " 'ask',\n",
       " 'around',\n",
       " 'bit',\n",
       " 'u',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'stubborn',\n",
       " 'didnt',\n",
       " 'even',\n",
       " 'want',\n",
       " 'go',\n",
       " 'hospit',\n",
       " 'kept',\n",
       " 'tell',\n",
       " 'mark',\n",
       " 'im',\n",
       " 'weak',\n",
       " 'sucker',\n",
       " 'hospit',\n",
       " 'weak',\n",
       " 'sucker',\n",
       " 'think',\n",
       " 'first',\n",
       " 'time',\n",
       " 'saw',\n",
       " 'class',\n",
       " 'gram',\n",
       " 'usual',\n",
       " 'run',\n",
       " 'like',\n",
       " 'ltgt',\n",
       " 'half',\n",
       " 'eighth',\n",
       " 'smarter',\n",
       " 'though',\n",
       " 'get',\n",
       " 'almost',\n",
       " 'whole',\n",
       " 'second',\n",
       " 'gram',\n",
       " 'ltgt',\n",
       " 'k',\n",
       " 'fyi',\n",
       " 'x',\n",
       " 'ride',\n",
       " 'earli',\n",
       " 'tomorrow',\n",
       " 'morn',\n",
       " 'he',\n",
       " 'crash',\n",
       " 'place',\n",
       " 'tonight',\n",
       " 'wow',\n",
       " 'never',\n",
       " 'realiz',\n",
       " 'embarass',\n",
       " 'accomod',\n",
       " 'thought',\n",
       " 'like',\n",
       " 'sinc',\n",
       " 'best',\n",
       " 'could',\n",
       " 'alway',\n",
       " 'seem',\n",
       " 'happi',\n",
       " 'cave',\n",
       " 'im',\n",
       " 'sorri',\n",
       " 'didnt',\n",
       " 'dont',\n",
       " 'give',\n",
       " 'im',\n",
       " 'sorri',\n",
       " 'offer',\n",
       " 'im',\n",
       " 'sorri',\n",
       " 'room',\n",
       " 'embarass',\n",
       " 'sm',\n",
       " 'ac',\n",
       " 'sptv',\n",
       " 'new',\n",
       " 'jersey',\n",
       " 'devil',\n",
       " 'detroit',\n",
       " 'red',\n",
       " 'wing',\n",
       " 'play',\n",
       " 'ice',\n",
       " 'hockey',\n",
       " 'correct',\n",
       " 'incorrect',\n",
       " 'end',\n",
       " 'repli',\n",
       " 'end',\n",
       " 'sptv',\n",
       " 'know',\n",
       " 'mallika',\n",
       " 'sherawat',\n",
       " 'yesterday',\n",
       " 'find',\n",
       " 'lturlgt',\n",
       " 'congrat',\n",
       " '1',\n",
       " 'year',\n",
       " 'special',\n",
       " 'cinema',\n",
       " 'pas',\n",
       " '2',\n",
       " 'call',\n",
       " '09061209465',\n",
       " 'c',\n",
       " 'suprman',\n",
       " 'v',\n",
       " 'matrix3',\n",
       " 'starwars3',\n",
       " 'etc',\n",
       " '4',\n",
       " 'free',\n",
       " 'bx420ip45w',\n",
       " '150pm',\n",
       " 'dont',\n",
       " 'miss',\n",
       " 'sorri',\n",
       " 'ill',\n",
       " 'call',\n",
       " 'later',\n",
       " 'meet',\n",
       " 'tell',\n",
       " 'reach',\n",
       " 'yesgauti',\n",
       " 'sehwag',\n",
       " 'odi',\n",
       " 'seri',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'pick',\n",
       " '1',\n",
       " 'burger',\n",
       " 'way',\n",
       " 'home',\n",
       " 'cant',\n",
       " 'even',\n",
       " 'move',\n",
       " 'pain',\n",
       " 'kill',\n",
       " 'ha',\n",
       " 'ha',\n",
       " 'ha',\n",
       " 'good',\n",
       " 'joke',\n",
       " 'girl',\n",
       " 'situat',\n",
       " 'seeker',\n",
       " 'part',\n",
       " 'check',\n",
       " 'iq',\n",
       " 'sorri',\n",
       " 'roommat',\n",
       " 'took',\n",
       " 'forev',\n",
       " 'ok',\n",
       " 'come',\n",
       " 'ok',\n",
       " 'lar',\n",
       " 'doubl',\n",
       " 'check',\n",
       " 'wif',\n",
       " 'da',\n",
       " 'hair',\n",
       " 'dresser',\n",
       " 'alreadi',\n",
       " 'said',\n",
       " 'wun',\n",
       " 'cut',\n",
       " 'v',\n",
       " 'short',\n",
       " 'said',\n",
       " 'cut',\n",
       " 'look',\n",
       " 'nice',\n",
       " 'valu',\n",
       " 'custom',\n",
       " 'plea',\n",
       " 'advis',\n",
       " 'follow',\n",
       " 'recent',\n",
       " 'review',\n",
       " 'mob',\n",
       " 'award',\n",
       " 'å£1500',\n",
       " 'bonu',\n",
       " 'prize',\n",
       " 'call',\n",
       " '09066364589',\n",
       " 'today',\n",
       " 'song',\n",
       " 'dedic',\n",
       " 'day',\n",
       " 'song',\n",
       " 'u',\n",
       " 'dedic',\n",
       " 'send',\n",
       " 'ur',\n",
       " 'valuabl',\n",
       " 'frnd',\n",
       " 'first',\n",
       " 'rpli',\n",
       " 'urgent',\n",
       " 'ur',\n",
       " 'award',\n",
       " 'complimentari',\n",
       " 'trip',\n",
       " 'eurodisinc',\n",
       " 'trav',\n",
       " 'acoentry41',\n",
       " 'å£1000',\n",
       " 'claim',\n",
       " 'txt',\n",
       " 'di',\n",
       " '87121',\n",
       " '186å£150morefrmmob',\n",
       " 'shracomorsglsuplt10',\n",
       " 'ls1',\n",
       " '3aj',\n",
       " 'hear',\n",
       " 'new',\n",
       " 'divorc',\n",
       " 'barbi',\n",
       " 'come',\n",
       " 'ken',\n",
       " 'stuff',\n",
       " 'plane',\n",
       " 'give',\n",
       " 'month',\n",
       " 'end',\n",
       " 'wah',\n",
       " 'lucki',\n",
       " 'man',\n",
       " 'save',\n",
       " 'money',\n",
       " 'hee',\n",
       " 'finish',\n",
       " 'class',\n",
       " 'hi',\n",
       " 'babe',\n",
       " 'im',\n",
       " 'home',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'someth',\n",
       " 'xx',\n",
       " 'kkwhere',\n",
       " 'youhow',\n",
       " 'perform',\n",
       " 'u',\n",
       " 'call',\n",
       " 'wait',\n",
       " 'machan',\n",
       " 'call',\n",
       " 'free',\n",
       " 'that',\n",
       " 'cool',\n",
       " 'gentleman',\n",
       " 'treat',\n",
       " 'digniti',\n",
       " 'respect',\n",
       " 'like',\n",
       " 'peopl',\n",
       " 'much',\n",
       " 'shi',\n",
       " 'pa',\n",
       " 'oper',\n",
       " 'ltgt',\n",
       " 'still',\n",
       " 'look',\n",
       " 'job',\n",
       " 'much',\n",
       " 'ta',\n",
       " 'earn',\n",
       " 'sorri',\n",
       " 'ill',\n",
       " 'call',\n",
       " 'later',\n",
       " 'k',\n",
       " 'call',\n",
       " 'ah',\n",
       " 'ok',\n",
       " 'way',\n",
       " 'home',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'place',\n",
       " 'man',\n",
       " 'yup',\n",
       " 'next',\n",
       " 'stop',\n",
       " 'call',\n",
       " 'later',\n",
       " 'dont',\n",
       " 'network',\n",
       " 'urgnt',\n",
       " 'sm',\n",
       " 'real',\n",
       " 'u',\n",
       " 'get',\n",
       " 'yo',\n",
       " 'need',\n",
       " '2',\n",
       " 'ticket',\n",
       " 'one',\n",
       " 'jacket',\n",
       " 'im',\n",
       " 'done',\n",
       " 'alreadi',\n",
       " 'use',\n",
       " 'multi',\n",
       " 'ye',\n",
       " 'start',\n",
       " 'send',\n",
       " 'request',\n",
       " 'make',\n",
       " 'pain',\n",
       " 'came',\n",
       " 'back',\n",
       " 'im',\n",
       " 'back',\n",
       " 'bed',\n",
       " 'doubl',\n",
       " 'coin',\n",
       " 'factori',\n",
       " 'got',\n",
       " 'ta',\n",
       " 'cash',\n",
       " 'nitro',\n",
       " 'im',\n",
       " 'realli',\n",
       " 'still',\n",
       " 'tonight',\n",
       " 'babe',\n",
       " 'ela',\n",
       " 'kanoil',\n",
       " 'download',\n",
       " 'come',\n",
       " 'wen',\n",
       " 'ur',\n",
       " 'free',\n",
       " 'yeah',\n",
       " 'don\\x89û÷t',\n",
       " 'stand',\n",
       " 'close',\n",
       " 'tho',\n",
       " 'you\\x89û÷ll',\n",
       " 'catch',\n",
       " 'someth',\n",
       " 'sorri',\n",
       " 'pain',\n",
       " 'ok',\n",
       " 'meet',\n",
       " 'anoth',\n",
       " 'night',\n",
       " 'spent',\n",
       " 'late',\n",
       " 'afternoon',\n",
       " 'casualti',\n",
       " 'mean',\n",
       " 'havent',\n",
       " 'done',\n",
       " 'stuff42moro',\n",
       " 'includ',\n",
       " 'time',\n",
       " 'sheet',\n",
       " 'sorri',\n",
       " 'smile',\n",
       " 'pleasur',\n",
       " 'smile',\n",
       " 'pain',\n",
       " 'smile',\n",
       " 'troubl',\n",
       " 'pour',\n",
       " 'like',\n",
       " 'rain',\n",
       " 'smile',\n",
       " 'sum1',\n",
       " 'hurt',\n",
       " 'u',\n",
       " 'smile',\n",
       " 'becoz',\n",
       " 'someon',\n",
       " 'still',\n",
       " 'love',\n",
       " 'see',\n",
       " 'u',\n",
       " 'smile',\n",
       " 'plea',\n",
       " 'call',\n",
       " 'custom',\n",
       " 'servic',\n",
       " 'repres',\n",
       " '0800',\n",
       " '169',\n",
       " '6031',\n",
       " '10am9pm',\n",
       " 'guarante',\n",
       " 'å£1000',\n",
       " 'cash',\n",
       " 'å£5000',\n",
       " 'prize',\n",
       " 'havent',\n",
       " 'plan',\n",
       " 'buy',\n",
       " 'later',\n",
       " 'check',\n",
       " 'alreadi',\n",
       " 'lido',\n",
       " 'got',\n",
       " '530',\n",
       " 'show',\n",
       " 'e',\n",
       " 'afternoon',\n",
       " 'u',\n",
       " 'finish',\n",
       " 'work',\n",
       " 'alreadi',\n",
       " 'free',\n",
       " 'rington',\n",
       " 'wait',\n",
       " 'collect',\n",
       " 'simpli',\n",
       " 'text',\n",
       " 'password',\n",
       " 'mix',\n",
       " '85069',\n",
       " 'verifi',\n",
       " 'get',\n",
       " 'usher',\n",
       " 'britney',\n",
       " 'fml',\n",
       " 'watch',\n",
       " 'telugu',\n",
       " 'moviewat',\n",
       " 'abt',\n",
       " 'u',\n",
       " 'see',\n",
       " 'finish',\n",
       " 'load',\n",
       " 'loan',\n",
       " 'pay',\n",
       " 'hi',\n",
       " 'wk',\n",
       " 'ok',\n",
       " 'hol',\n",
       " 'ye',\n",
       " 'bit',\n",
       " 'run',\n",
       " 'forgot',\n",
       " 'hairdress',\n",
       " 'appoint',\n",
       " 'four',\n",
       " 'need',\n",
       " 'get',\n",
       " 'home',\n",
       " 'n',\n",
       " 'shower',\n",
       " 'beforehand',\n",
       " 'caus',\n",
       " 'prob',\n",
       " 'u',\n",
       " 'ham',\n",
       " 'plea',\n",
       " 'dont',\n",
       " 'text',\n",
       " 'anymor',\n",
       " 'noth',\n",
       " 'el',\n",
       " 'say',\n",
       " 'okay',\n",
       " 'name',\n",
       " 'ur',\n",
       " 'price',\n",
       " 'long',\n",
       " 'legal',\n",
       " 'wen',\n",
       " 'pick',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=[]\n",
    "for i in list1:\n",
    "    for j in i:\n",
    "        final.append(j)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2691d9a-348d-41d1-95ec-958c64ad0775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
